\chapter{Hồi quy và Dự báo với Machine Learning}
\section{So sánh hồi quy truyền thống với ML}
Hồi quy truyền thống (như hồi quy tuyến tính) và Machine Learning (ML) có sự khác biệt rõ rệt về mô hình hóa dữ liệu, cách tiếp cận và mục tiêu tối ưu hóa. Dưới đây là một phân tích toán học chi tiết:

\subsubsection{Hồi quy truyền thống}
Hồi quy tuyến tính cổ điển có dạng:
\begin{equation}
    Y = X \beta + \varepsilon,
\end{equation}
trong đó:
\begin{itemize}
    \item $Y$ là biến phụ thuộc (đầu ra),
    \item $X$ là ma trận các biến độc lập (đặc trưng),
    \item $\beta$ là vector hệ số hồi quy,
    \item $\varepsilon$ là nhiễu có phân phối chuẩn $\mathcal{N}(0, \sigma^2)$.
\end{itemize}

Hệ số $\beta$ được ước lượng bằng phương pháp bình phương tối thiểu thông thường (OLS - Ordinary Least Squares):
\begin{equation}
    \hat{\beta} = (X^T X)^{-1} X^T Y.
\end{equation}

\subsubsection{Machine Learning trong Hồi quy}
Machine Learning sử dụng các mô hình phức tạp hơn như hồi quy Ridge, Lasso, và phương pháp phi tuyến như Random Forest, Neural Networks. Cách tiếp cận này có đặc điểm:

\paragraph{Ridge Regression:} Ổn định hóa bằng thêm một thành phần phạt $\lambda \|\beta\|^2$:
\begin{equation}
    \hat{\beta}_{ridge} = (X^T X + \lambda I)^{-1} X^T Y.
\end{equation}

\paragraph{Lasso Regression:} Sử dụng phạt $\ell_1$ để chọn biến:
\begin{equation}
    \hat{\beta}_{lasso} = \arg\min_\beta \left( \|Y - X\beta\|^2 + \lambda \|\beta\|_1 \right).
\end{equation}

\paragraph{Random Forest và Gradient Boosting:} Các mô hình dựa trên cây quyết định, không có dạng công thức đơn giản mà sử dụng tập hợp cây quyết định để dự báo.

\paragraph{Neural Networks:} Mô hình phi tuyến, tối ưu hóa dựa trên lan truyền ngược và hàm mất mát như:
\begin{equation}
    L = \sum_{i=1}^{n} (Y_i - f(X_i; \theta))^2.
\end{equation}

\subsection{So sánh Hiệu suất}
Các mô hình ML thường có hiệu suất tốt hơn khi dữ liệu phi tuyến hoặc có nhiều biến tương quan, nhưng yêu cầu nhiều dữ liệu hơn và tính toán phức tạp hơn.





\section{Mô hình XGBoost, Random Forest và hồi quy phi tuyến}
\subsection{Giới thiệu}
Mô hình XGBoost, Random Forest và hồi quy phi tuyến là các phương pháp mạnh mẽ trong Machine Learning để xử lý các quan hệ phi tuyến giữa biến đầu vào và đầu ra. Chúng giúp cải thiện độ chính xác dự báo so với các mô hình hồi quy tuyến tính truyền thống.

\subsection{Random Forest}
Random Forest (RF) là một tập hợp của nhiều cây quyết định, trong đó:
\begin{itemize}
    \item Mỗi cây được xây dựng từ một tập con ngẫu nhiên của dữ liệu.
    \item Kết quả cuối cùng được lấy trung bình (đối với bài toán hồi quy) hoặc theo số phiếu bầu (đối với phân loại).
\end{itemize}
Công thức dự báo của Random Forest được biểu diễn như sau:
\begin{equation}
    \hat{y} = \frac{1}{T} \sum_{t=1}^{T} f_t(x),
\end{equation}
trong đó $T$ là số lượng cây trong rừng, $f_t(x)$ là hàm dự đoán của cây thứ $t$.

\subsection{XGBoost}
XGBoost (Extreme Gradient Boosting) là một phương pháp tăng cường (boosting) dựa trên việc xây dựng cây quyết định tuần tự nhằm giảm thiểu hàm mất mát.
Hàm mất mát tổng thể trong XGBoost có dạng:
\begin{equation}
    L = \sum_{i=1}^{n} l(y_i, \hat{y}_i) + \sum_{t=1}^{T} \Omega(f_t),
\end{equation}
trong đó:
\begin{itemize}
    \item $l(y_i, \hat{y}_i)$ là hàm mất mát giữa giá trị thực và giá trị dự báo,
    \item $\Omega(f_t)$ là hàm điều chuẩn để kiểm soát độ phức tạp của cây quyết định.
\end{itemize}
Mô hình mới $F(x)$ được cập nhật theo công thức:
\begin{equation}
    F^{(t)}(x) = F^{(t-1)}(x) + \eta f_t(x),
\end{equation}
trong đó $\eta$ là tốc độ học.

\subsection{Hồi quy Phi tuyến}
Hồi quy phi tuyến mô tả mối quan hệ giữa biến đầu vào và đầu ra bằng một hàm phi tuyến như:
\begin{equation}
    y = f(x, \theta) + \varepsilon,
\end{equation}
trong đó $f(x, \theta)$ có thể là một hàm mũ, logarit, sigmoid hoặc một mạng nơ-ron.
Một số mô hình phổ biến:
\begin{itemize}
    \item Hồi quy đa thức: $y = \beta_0 + \beta_1 x + \beta_2 x^2 + \dots + \beta_p x^p + \varepsilon$.
    \item Hồi quy logarit: $y = \beta_0 + \beta_1 \log(x) + \varepsilon$.
    \item Hồi quy hàm mũ: $y = \beta_0 e^{\beta_1 x} + \varepsilon$.
\end{itemize}

\subsection{Kết luận}
Random Forest, XGBoost và hồi quy phi tuyến là các công cụ mạnh mẽ để dự báo và phân tích dữ liệu có tính phi tuyến, giúp cải thiện đáng kể độ chính xác so với mô hình tuyến tính truyền thống.






\section{Đánh giá mô hình dự báo (MAPE, RMSE, R-squared)}
\subsection{Giới thiệu}
Trong kinh tế lượng và machine learning, đánh giá mô hình dự báo là một bước quan trọng để kiểm tra mức độ chính xác của mô hình. Ba chỉ số phổ biến để đánh giá mô hình dự báo bao gồm:\\
- Sai số phần trăm tuyệt đối trung bình (Mean Absolute Percentage Error - MAPE) \\
- Căn bậc hai của trung bình bình phương sai số (Root Mean Square Error - RMSE) \\
- Hệ số xác định ($R^2$ - R-squared)

\subsection{Sai số phần trăm tuyệt đối trung bình (MAPE)}
MAPE đo lường sai số tương đối trung bình của các dự báo so với giá trị thực tế:
\begin{equation}
    \text{MAPE} = \frac{1}{n} \sum_{i=1}^{n} \left| \frac{y_i - \hat{y}_i}{y_i} \right| \times 100\%
\end{equation}
Trong đó:
\begin{itemize}
    \item $y_i$ là giá trị thực tế tại quan sát thứ $i$
    \item $\hat{y}_i$ là giá trị dự báo tại quan sát thứ $i$
    \item $n$ là số quan sát
\end{itemize}
Giá trị MAPE càng nhỏ thì mô hình dự báo càng chính xác.

\subsection{Căn bậc hai của trung bình bình phương sai số (RMSE)}
RMSE đo lường sai số dự báo trung bình theo đơn vị gốc của biến phụ thuộc:
\begin{equation}
    \text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
\end{equation}
RMSE càng nhỏ thì mô hình càng chính xác, vì sai số bình phương được giảm thiểu.

\subsection{Hệ số xác định ($R^2$ - R-squared)}
Hệ số xác định đo lường mức độ giải thích của biến độc lập đối với biến phụ thuộc:
\begin{equation}
    R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
\end{equation}
Trong đó $\bar{y}$ là giá trị trung bình của biến phụ thuộc. Giá trị $R^2$ nằm trong khoảng $[0,1]$, với $R^2$ càng gần 1 thì mô hình càng phù hợp.

\subsection{Kết luận}
Các chỉ số MAPE, RMSE, và $R^2$ cung cấp các cách tiếp cận khác nhau để đánh giá mô hình dự báo. Tùy vào mục tiêu phân tích mà ta có thể sử dụng từng chỉ số phù hợp.






\section{ML và các phương pháp Bayes trong dự báo kinh tế lượng}
\subsection{Giới thiệu}
Machine Learning (ML) và phương pháp Bayes ngày càng được sử dụng rộng rãi trong dự báo kinh tế lượng do khả năng xử lý dữ liệu lớn và cập nhật thông tin theo cách xác suất.

\subsection{Phương pháp Bayes trong Dự Báo}
Phương pháp Bayes dựa trên định lý Bayes:
\begin{equation}
    P(\theta | D) = \frac{P(D | \theta) P(\theta)}{P(D)}
\end{equation}
trong đó:
\begin{itemize}
    \item $P(\theta | D)$ là xác suất hậu nghiệm của tham số $\theta$ sau khi quan sát dữ liệu $D$.
    \item $P(D | \theta)$ là hàm khả năng (likelihood) của dữ liệu.
    \item $P(\theta)$ là xác suất tiên nghiệm của tham số $\theta$.
    \item $P(D)$ là xác suất biên của dữ liệu.
\end{itemize}

\subsubsection{Mô hình hồi quy Bayes}
Mô hình hồi quy Bayes mở rộng hồi quy tuyến tính thông qua cách tiếp cận xác suất:
\begin{equation}
    y = X \beta + \epsilon, \quad \epsilon \sim \mathcal{N}(0, \sigma^2 I)
\end{equation}
Trong mô hình Bayes, $\beta$ được xem là một biến ngẫu nhiên với phân phối tiên nghiệm $P(\beta)$, thường được chọn là phân phối Gauss:
\begin{equation}
    \beta \sim \mathcal{N}(\mu_0, \Sigma_0)
\end{equation}
Khi có dữ liệu quan sát, phân phối hậu nghiệm của $\beta$ cũng là một phân phối Gauss:
\begin{equation}
    P(\beta | D) \propto P(D | \beta) P(\beta)
\end{equation}

\subsubsection{Ước lượng bằng phương pháp Bayes}
Giá trị kỳ vọng của $\beta$ trong mô hình hồi quy Bayes được tính như sau:
\begin{equation}
    \mathbb{E}[\beta | D] = (X^TX + \Sigma_0^{-1})^{-1} (X^T y + \Sigma_0^{-1} \mu_0)
\end{equation}
\begin{equation}
    \text{Var}(\beta | D) = (X^TX + \Sigma_0^{-1})^{-1} \sigma^2
\end{equation}

\subsection{Kết hợp Machine Learning và Bayes trong Dự Báo}
\subsubsection{Bayesian Neural Networks (BNN)}
Mạng nơ-ron Bayes sử dụng phân phối tiên nghiệm trên các trọng số $W$:
\begin{equation}
    P(W | D) = \frac{P(D | W) P(W)}{P(D)}
\end{equation}
BNN thường được huấn luyện bằng các phương pháp xấp xỉ như Variational Inference (VI) hoặc Markov Chain Monte Carlo (MCMC).

\subsubsection{Gaussian Processes (GP) trong dự báo kinh tế}
Mô hình Gaussian Process (GP) có thể được sử dụng trong dự báo thời gian với phân phối tiên nghiệm Gauss:
\begin{equation}
    f(x) \sim \mathcal{GP}(m(x), k(x, x'))
\end{equation}
Trong đó:
\begin{itemize}
    \item $m(x)$ là hàm trung bình.
    \item $k(x, x')$ là hàm hiệp phương sai (kernel function).
\end{itemize}

\subsection{Kết luận}
Phương pháp Bayes mang lại lợi thế trong dự báo kinh tế lượng nhờ khả năng cập nhật thông tin và biểu diễn sự không chắc chắn trong mô hình. Kết hợp Machine Learning với Bayesian Inference giúp tăng độ chính xác và tính linh hoạt của các mô hình dự báo.